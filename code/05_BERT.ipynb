{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8c34d7",
   "metadata": {},
   "source": [
    "## Goal of the notebook\n",
    "\n",
    "The scores for classical ML methods are quite low at around 65%. This is because these methods\n",
    "are not accounting for the context in the text. So using a method which takes into account the\n",
    "context would likely give better accuracy scores. So I will try to implement a basic BERT model in this notebook.\n",
    "\n",
    "About BERT:\n",
    "\n",
    "> BERT’s key technical innovation is applying the bidirectional training of Transformer, a popular attention model, to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or combined left-to-right and right-to-left training. \n",
    "\n",
    "We are basically using transfer learning for a specific task of sarcasm detection.\n",
    "\n",
    "## How BERT works?\n",
    "\n",
    "> *As opposed to directional models, which read the text input sequentially (left-to-right or right-to-left), the Transformer encoder reads the entire sequence of words at once. Therefore it is considered bidirectional, though it would be more accurate to say that it’s non-directional. This characteristic allows the model to learn the context of a word based on all of its surroundings (left and right of the word).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebbaa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras \n",
    "import tensorflow_text as text \n",
    "\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                            confusion_matrix, \n",
    "                            classification_report,ConfusionMatrixDisplay,\n",
    "                            plot_confusion_matrix)\n",
    "\n",
    "# from keras import backend as K\n",
    "# from tensorflow.keras.preprocessing import sequence\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from keras.layers import LSTM,Dense,Bidirectional,Input\n",
    "# from keras.models import Model\n",
    "# import torch\n",
    "# import transformers \n",
    "# from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d634371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(73)#to maintain reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fbec57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_json('../data/Sarcasm_Headlines_Dataset.json',lines=True)#using original dataset as BERT has preprocessing abilities\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f609ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['headline']#creating X and y variables\n",
    "y = df['is_sarcastic']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f123e7",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1678136c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14075    tight wisconsin house primary too close to cal...\n",
       "6861     labor dept. creates 20,000 new hobbies for nat...\n",
       "20106    fired u.s. attorney preet bharara said to have...\n",
       "8679     bosnian gum company introduces new war-flavore...\n",
       "24542    adele sends her love to brussels with touching...\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928a7fe",
   "metadata": {},
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c9daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 15:18:00.895287: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ebf4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054671ff",
   "metadata": {},
   "source": [
    "### Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f9ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "668/668 [==============================] - 11964s 18s/step - loss: 0.5328 - accuracy: 0.7457 - val_loss: 0.4920 - val_accuracy: 0.7757\n",
      "Epoch 2/5\n",
      "668/668 [==============================] - 4521s 7s/step - loss: 0.5048 - accuracy: 0.7608 - val_loss: 0.4908 - val_accuracy: 0.7864\n",
      "Epoch 3/5\n",
      "668/668 [==============================] - 8083s 12s/step - loss: 0.4908 - accuracy: 0.7697 - val_loss: 0.4712 - val_accuracy: 0.7694\n",
      "Epoch 4/5\n",
      "594/668 [=========================>....] - ETA: 6:35 - loss: 0.4799 - accuracy: 0.7759"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # only using accuracy metric here\n",
    "history = model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=5, batch_size = 32) # for 5 epochs, can be increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f696b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for test data\n",
    "y_predicted = model.predict(X_test)\n",
    "y_predicted = y_predicted.flatten()\n",
    "print(y_predicted[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7bac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold\n",
    "t = .5\n",
    "# if a value is greater than or equal to 0.5 then it's a 1 else 0\n",
    "y_predicted = [1 if x>=t else 0 for x in y_predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50446eb9",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121e07d",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb475e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_predicted)\n",
    "print('Confusion Matrix: \\n')\n",
    "print(matrix)\n",
    "# Convert to a pandas dataframe\n",
    "confusion_df = pd.DataFrame(matrix, index=['0','1'], columns=['0','1'])\n",
    "\n",
    "# Set the names of the x and y axis, this helps with the readability of the heatmap.\n",
    "confusion_df.index.name = 'True Label'\n",
    "confusion_df.columns.name = 'Predicted Label'\n",
    "sns.heatmap(confusion_df, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86712113",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6aeaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_predicted)\n",
    "print('accuracy:')\n",
    "print(round(acc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaba4f2",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbfd2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_predicted)\n",
    "print('Precision score:')\n",
    "print(round(precision,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb3ac9",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc65308",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(y_test, y_predicted)\n",
    "print('Recall score:')\n",
    "print(round(recall,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1062c",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "\n",
    "- **For 5 epochs accuracy is 77% which is 18% higher than baseline  and also significantly greater than the accuracy scores produced by classical ML methods.**\n",
    "- **Context is taken into account which results in better scores. We can increase the number of epochs to possibly get even better scores.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577eedb9",
   "metadata": {},
   "source": [
    "**Reference**:\n",
    "\n",
    "- https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270    \n",
    "- https://www.analyticsvidhya.com/blog/2021/12/text-classification-using-bert-and-tensorflow/ \n",
    "- https://towardsdatascience.com/multi-label-text-classification-using-bert-and-tensorflow-d2e88d8f488d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
