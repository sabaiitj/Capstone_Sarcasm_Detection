{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b838279",
   "metadata": {},
   "source": [
    "## Goal of the notebook\n",
    "\n",
    "In this notebook I will be using countvectorized dataframe, then I will be selecting 100 top features by SelectKBest( ) and use them further to model. I will be running two models here:\n",
    "\n",
    "- RandomForestClassifier( )\n",
    "- LogisticRegression( )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4423de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV,KFold,StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                            confusion_matrix, \n",
    "                            classification_report,ConfusionMatrixDisplay,\n",
    "                            plot_confusion_matrix)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "\n",
    "np.random.seed(73) #to maintain consistency in reproducibility of same numbers across\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ea4686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>abort</th>\n",
       "      <th>abus</th>\n",
       "      <th>accept</th>\n",
       "      <th>...</th>\n",
       "      <th>INTJ_proportion</th>\n",
       "      <th>X_proportion</th>\n",
       "      <th>AUX_proportion</th>\n",
       "      <th>CCONJ_proportion</th>\n",
       "      <th>PART_proportion</th>\n",
       "      <th>PROPN_proportion</th>\n",
       "      <th>PUNCT_proportion</th>\n",
       "      <th>ADJ_proportion</th>\n",
       "      <th>SCONJ_proportion</th>\n",
       "      <th>VERB_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1023 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic  num_words  num_unique_words  num_chars  num_stopwords  \\\n",
       "0           0.0       12.0              12.0       78.0            2.0   \n",
       "1           0.0       14.0              14.0       84.0            6.0   \n",
       "2           1.0       14.0              13.0       79.0            4.0   \n",
       "3           1.0       13.0              13.0       84.0            5.0   \n",
       "4           0.0       11.0              11.0       64.0            3.0   \n",
       "\n",
       "   num_punctuations  mean_word_len  abort  abus  accept  ...  INTJ_proportion  \\\n",
       "0               2.0       5.583333    0.0   0.0     0.0  ...              0.0   \n",
       "1               3.0       5.071429    0.0   0.0     0.0  ...              0.0   \n",
       "2               1.0       4.714286    0.0   0.0     0.0  ...              0.0   \n",
       "3               2.0       5.538462    0.0   0.0     0.0  ...              0.0   \n",
       "4               2.0       4.909091    0.0   0.0     0.0  ...              0.0   \n",
       "\n",
       "   X_proportion  AUX_proportion  CCONJ_proportion  PART_proportion  \\\n",
       "0           0.0             0.0               0.0              0.0   \n",
       "1           0.0             0.0               0.0              0.0   \n",
       "2           0.0             0.0               0.0              0.0   \n",
       "3           0.0             0.0               0.0              0.0   \n",
       "4           0.0             0.0               0.0              0.0   \n",
       "\n",
       "   PROPN_proportion  PUNCT_proportion  ADJ_proportion  SCONJ_proportion  \\\n",
       "0          0.000000               0.0        0.400000               0.0   \n",
       "1          0.625000               0.0        0.125000               0.0   \n",
       "2          0.333333               0.0        0.111111               0.0   \n",
       "3          0.111111               0.0        0.111111               0.0   \n",
       "4          0.428571               0.0        0.000000               0.0   \n",
       "\n",
       "   VERB_proportion  \n",
       "0         0.100000  \n",
       "1         0.000000  \n",
       "2         0.222222  \n",
       "3         0.333333  \n",
       "4         0.142857  \n",
       "\n",
       "[5 rows x 1023 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Vectorised_Data.csv')#importing vectorised dataframe \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4334eace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26703, 1023)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape# shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37ed6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_sarcastic        0\n",
       "num_words           0\n",
       "num_unique_words    0\n",
       "num_chars           0\n",
       "num_stopwords       0\n",
       "                   ..\n",
       "PROPN_proportion    0\n",
       "PUNCT_proportion    0\n",
       "ADJ_proportion      0\n",
       "SCONJ_proportion    0\n",
       "VERB_proportion     0\n",
       "Length: 1023, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2462c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any nulls\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594d904",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bedb28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.is_sarcastic\n",
    "X = df[[cols for cols in df.columns if cols != \"is_sarcastic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e72b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                   test_size = 0.20,stratify=y)\n",
    "#stratification as dataframe was not balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc877b",
   "metadata": {},
   "source": [
    "## Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dedfbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9bcea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "ss = StandardScaler()\n",
    "\n",
    "# fit on Train\n",
    "X_train_ss = pd.DataFrame(ss.fit_transform(X_train),\n",
    "                          columns = X_train.columns,\n",
    "                          index = X_train.index)\n",
    "\n",
    "# transform test\n",
    "X_test_ss = pd.DataFrame(ss.transform(X_test),\n",
    "                         columns = X_test.columns,\n",
    "                         index = X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4196db9",
   "metadata": {},
   "source": [
    "## Select KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73093b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692a7836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = SelectKBest(k=100)\n",
    "selector.fit(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c83f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9faf4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_feat_select->train df created from selected features \n",
    "#X_test_feat_select->test df created from selected features \n",
    "X_train_feat_select = X_train_ss.iloc[:,cols]\n",
    "X_test_feat_select = X_test_ss.iloc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b589d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed_cols-> columns removed after SelectKBest( )\n",
    "#X_train_feat_removed-> df created from X_train containing columns removed after SelectKBest( )\n",
    "#X_test_feat_removed->df created from X_test containing columns removed after SelectKBest( )\n",
    "removed_cols = [c for c in X_train_ss.columns if c not in X_train_feat_select.columns]\n",
    "X_train_feat_removed = X_train_ss.loc[:,removed_cols]\n",
    "X_test_feat_removed = X_test_ss.loc[:,removed_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9883ea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_words', 'num_unique_words', 'num_chars', 'num_stopwords',\n",
       "       'num_punctuations', 'mean_word_len', 'alreadi', 'america', 'announc',\n",
       "       'answer', 'artist', 'assur', 'biden', 'card', 'case', 'christian',\n",
       "       'commerci', 'communiti', 'conserv', 'consid', 'cost', 'court', 'cowork',\n",
       "       'critic', 'deep', 'documentari', 'dog', 'dress', 'drink', 'drunk',\n",
       "       'educ', 'excit', 'eye', 'fear', 'financi', 'fuck', 'guy', 'happi',\n",
       "       'harass', 'heart', 'honor', 'increas', 'incred', 'interview',\n",
       "       'introduc new', 'journalist', 'kick', 'law', 'loss', 'magazin', 'magic',\n",
       "       'manag', 'muslim', 'nation', 'netflix', 'number', 'olymp', 'order',\n",
       "       'paper', 'perform', 'player', 'poor', 'pound', 'presid', 'pretti',\n",
       "       'prevent', 'price', 'primari', 'progress', 'race', 'ralli', 'recommend',\n",
       "       'refus', 'relat', 'repeal', 'road', 'robert', 'rubio', 'sign', 'sinc',\n",
       "       'sleep', 'someon', 'space', 'spend', 'straight', 'street', 'stun',\n",
       "       'sudden', 'suprem court', 'sure', 'teacher', 'terror', 'texa', 'touch',\n",
       "       'trump', 'union', 'user', 'water', 'wonder', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected Columns\n",
    "X_train_feat_select.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6cda8",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069774b5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6b0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfscore2(X_train, X_test, y_train, y_test,n_estimators,max_depth):\n",
    "   \n",
    "    '''Gridsearching RandomForest'''\n",
    "   \n",
    "    y_test= y_test.values.ravel()\n",
    "    y_train = y_train.values.ravel()\n",
    "    rf_params = {\n",
    "             'n_estimators':n_estimators,\n",
    "             'max_depth':max_depth}   # parameters for grid search\n",
    "    \n",
    "    rf_gs = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, verbose=1, n_jobs=-1)\n",
    "    rf_gs.fit(X_train,y_train) # training the random forest with all possible parameters\n",
    "    print('GridSearch results')\n",
    "    print('The best parameters on the training data are:\\n',rf_gs.best_params_) # printing the best parameters\n",
    "    max_depth_best = rf_gs.best_params_['max_depth']      # getting the best max_depth\n",
    "    n_estimators_best = rf_gs.best_params_['n_estimators']  # getting the best n_estimators\n",
    "    print(\"best max_depth:\",max_depth_best)\n",
    "    print(\"best n_estimators:\",n_estimators_best)\n",
    "    best_rf_gs = RandomForestClassifier(max_depth=max_depth_best,n_estimators=n_estimators_best) # instantiate the best model\n",
    "    \n",
    "    score(best_rf_gs, 'Random Forest', X_train, y_train)\n",
    "    \n",
    "    best_rf_gs.fit(X_train,y_train)  # fitting the best model\n",
    "\n",
    "    preds = best_rf_gs.predict(X_test)\n",
    "    print(\"\")\n",
    "    \n",
    "    disp = plot_confusion_matrix(best_rf_gs, X_test, y_test)\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
    "    plt.show();\n",
    "    \n",
    "    print(classification_report(y_test,preds))\n",
    "    print(accuracy_score(y_test, preds))\n",
    "\n",
    "    \n",
    "    print('Features and their importance:\\n')\n",
    "    feature_importances = pd.Series(best_rf_gs.feature_importances_, index=X_train.columns).sort_values().tail(10)\n",
    "    print(feature_importances.plot(kind=\"barh\", figsize=(6,6)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61110bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, name, X, y):\n",
    "    '''Cross val score for specific model, df and target'''\n",
    "    cv = StratifiedKFold(n_splits=10,\n",
    "                         random_state=42,\n",
    "                         shuffle=True)\n",
    "    s = cross_val_score(model, X, y, cv=cv,\n",
    "                        n_jobs=-1)\n",
    "    print('{} Score: {:.2f} +- {:.3f}'.format(name, \n",
    "                                              s.mean(), \n",
    "                                              2 * s.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82dbde42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n",
      "GridSearch results\n",
      "The best parameters on the training data are:\n",
      " {'max_depth': 21, 'n_estimators': 60}\n",
      "best max_depth: 21\n",
      "best n_estimators: 60\n",
      "Random Forest Score: 0.65 +- 0.017\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[2395  599]\n",
      " [1245 1102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.80      0.72      2994\n",
      "         1.0       0.65      0.47      0.54      2347\n",
      "\n",
      "    accuracy                           0.65      5341\n",
      "   macro avg       0.65      0.63      0.63      5341\n",
      "weighted avg       0.65      0.65      0.64      5341\n",
      "\n",
      "0.654746302190601\n",
      "Features and their importance:\n",
      "\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = list(range(10,100,10))\n",
    "max_depth = list(range(1, 30, 2)) \n",
    "rfscore2(X_train_feat_select, X_test_feat_select, y_train, y_test,n_estimators,max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2fe091",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "    \n",
    "- num_chars, num_stopwords, mean_word_len, num_punctuations are among most relevant features\n",
    "  with highest values of coefficients.\n",
    "- The model RandomForestClassifier here is 65% accurate in predicting the target class. \n",
    "- This is 9% more accurate than our baseline model with 56% accuracy.\n",
    "- It was more precise in predicting the \"0\" class(non-sarcastic), with a precision of 66%.\n",
    "  The precision for predicting \"No\" is 65%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8808de03",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da745623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(solver='saga')\n",
      "{'penalty': 'l2', 'solver': 'saga'}\n",
      "\n",
      "Baseline: 56%\n",
      "\n",
      "Best Score: 0.6171\n",
      "Test Score: 0.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg_params = {'penalty': ['l1', 'l2'], \n",
    "                 'solver': ['liblinear', 'saga'],\n",
    "                }\n",
    "\n",
    "logreg_gridsearch = GridSearchCV(LogisticRegression(), \n",
    "                                 logreg_params, \n",
    "                                 cv=5, \n",
    "                                 n_jobs=-1)\n",
    "\n",
    "logreg_gridsearch.fit(X_train_feat_select, y_train.values.ravel())\n",
    "\n",
    "print(logreg_gridsearch.best_estimator_)\n",
    "print(logreg_gridsearch.best_params_)\n",
    "\n",
    "print('\\nBaseline: 56%')\n",
    "\n",
    "print('\\nBest Score:', round(logreg_gridsearch.best_score_, 4))\n",
    "print('Test Score:', round(logreg_gridsearch.score(X_test_feat_select, y_test.values.ravel()), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cef4c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 56%\n",
      "\n",
      "Train scores: [0.62508776 0.62344957 0.61657303 0.60884831 0.61985019]\n",
      "Mean: 0.619\n",
      "Stdev: 0.012 \n",
      "\n",
      "Test scores: [0.59681946 0.64138577 0.61797753 0.63576779 0.6329588 ]\n",
      "Mean: 0.625\n",
      "Stdev: 0.032 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=500, \n",
    "                            penalty='l2', \n",
    "                            solver='saga')\n",
    "\n",
    "logreg.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "train_scores = cross_val_score(logreg, X_train_feat_select, y_train.values.ravel())\n",
    "print('Baseline: 56%\\n')\n",
    "\n",
    "print('Train scores:', train_scores)\n",
    "print('Mean:', round(train_scores.mean(), 3))\n",
    "print('Stdev:', round(2 * train_scores.std(), 3), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f905a2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_punctuations</td>\n",
       "      <td>-0.284690</td>\n",
       "      <td>0.284690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>NOUN_proportion</td>\n",
       "      <td>-0.250276</td>\n",
       "      <td>0.250276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num_stopwords</td>\n",
       "      <td>-0.240278</td>\n",
       "      <td>0.240278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>case</td>\n",
       "      <td>-0.201521</td>\n",
       "      <td>0.201521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>america</td>\n",
       "      <td>-0.194371</td>\n",
       "      <td>0.194371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.186170</td>\n",
       "      <td>0.186170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>PROPN_proportion</td>\n",
       "      <td>-0.185788</td>\n",
       "      <td>0.185788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>announc</td>\n",
       "      <td>0.184189</td>\n",
       "      <td>0.184189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>pretti</td>\n",
       "      <td>0.175026</td>\n",
       "      <td>0.175026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>muslim</td>\n",
       "      <td>-0.171703</td>\n",
       "      <td>0.171703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>manag</td>\n",
       "      <td>0.159294</td>\n",
       "      <td>0.159294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_words</td>\n",
       "      <td>0.153174</td>\n",
       "      <td>0.153174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>dead</td>\n",
       "      <td>-0.151680</td>\n",
       "      <td>0.151680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>guy</td>\n",
       "      <td>-0.150887</td>\n",
       "      <td>0.150887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>fear</td>\n",
       "      <td>0.149825</td>\n",
       "      <td>0.149825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>year</td>\n",
       "      <td>0.148635</td>\n",
       "      <td>0.148635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>olymp</td>\n",
       "      <td>0.145550</td>\n",
       "      <td>0.145550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>biden</td>\n",
       "      <td>0.144975</td>\n",
       "      <td>0.144975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>perform</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>0.144765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>order</td>\n",
       "      <td>-0.140627</td>\n",
       "      <td>0.140627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              features      coef       abs\n",
       "4     num_punctuations -0.284690  0.284690\n",
       "1008   NOUN_proportion -0.250276  0.250276\n",
       "3        num_stopwords -0.240278  0.240278\n",
       "142               case -0.201521  0.201521\n",
       "38             america -0.194371  0.194371\n",
       "265                dog  0.186170  0.186170\n",
       "1017  PROPN_proportion -0.185788  0.185788\n",
       "43             announc  0.184189  0.184189\n",
       "674             pretti  0.175026  0.175026\n",
       "585             muslim -0.171703  0.171703\n",
       "540              manag  0.159294  0.159294\n",
       "0            num_words  0.153174  0.153174\n",
       "234               dead -0.151680  0.151680\n",
       "390                guy -0.150887  0.150887\n",
       "329               fear  0.149825  0.149825\n",
       "1001              year  0.148635  0.148635\n",
       "615              olymp  0.145550  0.145550\n",
       "97               biden  0.144975  0.144975\n",
       "641            perform -0.144765  0.144765\n",
       "618              order -0.140627  0.140627"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Coefficient Interpretation\n",
    "logreg_coefs_0 = pd.DataFrame(list(zip(X_train_feat_select.columns, np.expm1(logreg.coef_[0]))), \n",
    "                           columns=['features', 'coef'])\n",
    "\n",
    "logreg_coefs_0['abs'] = abs(logreg_coefs_0['coef'])\n",
    "\n",
    "logreg_coefs_0.sort_values('abs', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf47858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and their importance for Logistic regression:\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logreg_coefs_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatures and their importance for Logistic regression:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m (\u001b[43mlogreg_coefs_0\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarh\u001b[39m\u001b[38;5;124m\"\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg_coefs_0' is not defined"
     ]
    }
   ],
   "source": [
    "print('Features and their importance for Logistic regression:\\n')\n",
    "(logreg_coefs_0.sort_values('abs', ascending=False)).plot(kind=\"barh\", figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test,preds))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,preds))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19189cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conmat = np.array(confusion_matrix(y_test, \n",
    "                                   logreg.predict(X_test), \n",
    "                                   labels=[0, 1, 2]))\n",
    "\n",
    "print(classification_report(y_test,\n",
    "                            logreg.predict(X_test), \n",
    "                            target_names=['No', \"Don't know\", 'Yes']))\n",
    "\n",
    "matrix_display = ConfusionMatrixDisplay(confusion_matrix=conmat, \n",
    "                                        display_labels=logreg.classes_)\n",
    "matrix_display.plot()\n",
    "\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(10, 10)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44c957",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "    \n",
    "- The features with the largest absolute coefficients are mostly the same across the two \n",
    "  models.\n",
    "- num_punctuations,NOUN_proportion, num_stopwords are among most relevant features with\n",
    "  highest values of coefficients.\n",
    "- Accuracy on test data is 62.5% which is 6.5% higher than baseline\n",
    "- the best solver for logistic regression model here is 'saga'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0846167d",
   "metadata": {},
   "source": [
    "## Conclusion for this notebook :\n",
    "\n",
    "- RandomForest performed better than Logistic regression in terms of accuracy\n",
    "- The models are not really able to capture the context of the text, no bigrams or trigrams are coming as really relevant which leads to low accuracy scores since sarcasm detection is very subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cfdf3f",
   "metadata": {},
   "source": [
    "## Way Forward\n",
    "\n",
    "- I want to see whether particular linear combinations of certain words do well \n",
    "  for detecting sarcasm or not. For that I want to try PCA on all columns, and use   the resulting dataframe to model again. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
