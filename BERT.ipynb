{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8c34d7",
   "metadata": {},
   "source": [
    "## Goal of the notebook\n",
    "\n",
    "The scores for classical ML methods are quite low at around 65%. This is because these methods\n",
    "are not accounting for the context in the text. So using a method which takes into account the\n",
    "context would likely give better accuracy scores. So I will try to implement a basic BERT model in this notebook.\n",
    "\n",
    "About BERT:\n",
    "\n",
    "> BERT’s key technical innovation is applying the bidirectional training of Transformer, a popular attention model, to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or combined left-to-right and right-to-left training. \n",
    "\n",
    "We are basically using transfer learning for a specific task of sarcasm detection.\n",
    "\n",
    "### How BERT works?\n",
    "\n",
    "> *As opposed to directional models, which read the text input sequentially (left-to-right or right-to-left), the Transformer encoder reads the entire sequence of words at once. Therefore it is considered bidirectional, though it would be more accurate to say that it’s non-directional. This characteristic allows the model to learn the context of a word based on all of its surroundings (left and right of the word).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebbaa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras \n",
    "import tensorflow_text as text \n",
    "\n",
    "# from keras import backend as K\n",
    "# from tensorflow.keras.preprocessing import sequence\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from keras.layers import LSTM,Dense,Bidirectional,Input\n",
    "# from keras.models import Model\n",
    "# import torch\n",
    "# import transformers \n",
    "# from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d634371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(73)#to maintain reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fbec57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_json('Sarcasm_Headlines_Dataset.json',lines=True)#using original dataset as BERT has preprocessing abilities\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f609ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['headline']\n",
    "y = df['is_sarcastic']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1678136c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24564    nfl player shares some good news about his dau...\n",
       "5708              trumplethinskin: a president's day fable\n",
       "5247     tragic oscar-night camera malfunction leaves s...\n",
       "8051     hawaii's politics: surf, aloha aina, and dusti...\n",
       "10011    officials warn flint residents that some areas...\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62c9daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text in /usr/local/anaconda3/lib/python3.9/site-packages (2.9.0)\n",
      "Requirement already satisfied: tensorflow<2.10,>=2.9.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow-text) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow-text) (0.12.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (14.0.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.19.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.47.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.12)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (21.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (4.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.22.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (61.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 19:20:31.321877: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ebf4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24f9ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "668/668 [==============================] - 5266s 8s/step - loss: 0.5981 - accuracy: 0.6859\n",
      "Epoch 2/2\n",
      "668/668 [==============================] - 9683s 14s/step - loss: 0.5223 - accuracy: 0.7480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4e1eb6970>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # only using accuracy metric here\n",
    "model.fit(X_train, y_train, epochs=2, batch_size = 32) # for 2 epochs, can be increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f696b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1370s 8s/step\n",
      "[0.27970657 0.2746869  0.22747366 ... 0.921731   0.5657078  0.51149374]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted = y_predicted.flatten()\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1062c",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "\n",
    "- **For 2 epochs accuracy is 74.80 which is 18% higher than baseline and also significantly greater than the accuracy scores produced by classical ML methods.**\n",
    "- **Context is taken into account which results in better scores. We can increase the number of epochs to possibly get even better scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577eedb9",
   "metadata": {},
   "source": [
    "**Reference**:\n",
    "\n",
    "- https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270    \n",
    "- https://www.analyticsvidhya.com/blog/2021/12/text-classification-using-bert-and-tensorflow/ \n",
    "- https://towardsdatascience.com/multi-label-text-classification-using-bert-and-tensorflow-d2e88d8f488d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
